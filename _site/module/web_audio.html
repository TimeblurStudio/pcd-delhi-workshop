<!DOCTYPE html>
<html>
<head>

	<title>WEB AUDIO API</title>
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/main.css">
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/highlighter.css">
	<script type="text/javascript" src="/pcd-delhi-workshop/scripts/prefixfree.min.js"></script>
</head>
<body>

	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/topbar.css">
<div id="topbar">
	<div id="links">
		<a href="/pcd-delhi-workshop/">home</a>
		<span>|</span>
		<a href="/pcd-delhi-workshop/syllabus">workshop</a>
	</div>
	<div id="bar">
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
	</div>
</div>


	<h1>Web Audio API</h1>

	<p>First there were two specs. Web Audio API (pushed by Google) won out over Audio Data API (originally pushed by Mozilla) because it included natively built components instead of just signal processing in javascript (which at the time especially, JS was not fast enough).</p>

<p>The <a href="https://webaudio.github.io/web-audio-api/">Web Audio API</a> is a specification, and, like other web specifications, has to be agreed upon by all participants. The process is open and managed by the W3C.</p>

<p>These participants are a collection of browser makers, audio industry professionals and enthusiasts. If you have an issue or feature you’d like to see included in the specification, you can add a <a href="https://github.com/WebAudio/web-audio-api">github issue</a>.</p>

<h3 id="audiocontext">AudioContext</h3>

<p>The AudioContext is the parent entity of all the rest of the features of the Web Audio API. To make any node, first you have to make the AudioContext.</p>

<p>Since this is such a fundamental thing, in Tone.js the AudioContext is created for you when Tone.js is loaded.</p>

<p>All nodes are created from the AudioContext using methods like <code class="highlighter-rouge">audioContext.createOscillator()</code>. Tone.js abstracts away these calls to the underlying AudioContext.</p>

<p>All nodes created and scheduled on the AudioContext comprise the “processing graph”. The processing graph is basically all of the scheduling, routing, and math logic from audio sources to the final output (your speakers).</p>

<p>The processing is done in chunks of 128 samples according to the specification.</p>

<h2 id="components">Components</h2>

<p>There are two basic types in the Web Audio API, AudioNodes and AudioParams.</p>

<h3 id="audionode">AudioNode</h3>

<p>The audio nodes are the sources or effects which will often accept an incoming connection from an audio node and produce an output connection to another audio node.</p>

<p>AudioNodes includes things like oscillators, buffer player, filter, delay, compressor.</p>

<p>They have a <code class="highlighter-rouge">connect</code> method which will route the processed audio from one node to another. If they are not a source node (like an oscillator), they will also receive connections from other nodes.</p>

<h3 id="audioparam">AudioParam</h3>

<p>AudioNodes will usually have one or more AudioParams.</p>

<p>AudioParams are like the knobs on an audio module or effect in that they let you adjust and control the parameters of the components. Unlike a knob, you can schedule it to ramp and change in precise ways.</p>

<p>An example of an AudioParam is the frequency attribute of an OscillatorNode. <code class="highlighter-rouge">frequency</code> is not a number, but an AudioParam which means that it can be precisely scheduled.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">//change the frequency value to 220 at a precise moment</span>
<span class="nx">oscillator</span><span class="p">.</span><span class="nx">frequency</span><span class="p">.</span><span class="nx">setValueAtTime</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="c1">//then ramp the value up to 440 over 1 second</span>
<span class="nx">oscillator</span><span class="p">.</span><span class="nx">frequency</span><span class="p">.</span><span class="nx">linearRampToValue</span><span class="p">(</span><span class="mi">440</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="scheduling">Scheduling</h3>

<p>Nearly everything in the Web Audio API can be precisely (sample-accurately) scheduled according to the AudioContext time. This is vital for creating sound and music.</p>


	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/footer.css">
<div id='footnotes'>

</div>
<div id='footer'>
	©2019 PCD, Delhi <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA </a>
	&
	©2017-2018 Yotam Mann <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>
</div>

	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90915308-1', 'auto');
  ga('send', 'pageview');

</script>

	<script type="text/javascript">

	// jsfiddle creates too many AudioContexts, 
	// need to insure that the offscreen fiddles are closed
	// to remove the unused AudioContexts

	function isOffScreen (el) {
		var rect = el.getBoundingClientRect();
		return ((rect.left + rect.width) < 0 
			|| (rect.top + rect.height) < 0
			|| (rect.left > window.innerWidth || rect.top > window.innerHeight))
	}

	function reloadIframe(iframe){
		var url = iframe.src
		iframe.src = 'about:blank'
		setTimeout(function() {
			iframe.src = url
		}, 10)
	}

	//test the active elements to see if they are out of the viewport
	setInterval(function(){
		document.querySelectorAll('.active-iframe').forEach(function(el){
			if (isOffScreen(el)){
				reloadIframe(el)
				el.classList.remove('active-iframe')
			}
		})
	}, 1000)

	window.addEventListener('message', function(e){
		// if the results tab was selected
		var resultsTab = e.data[0] === 'resultsFrame'
		var slug = e.data[1].slug
		// get the iframe element using the slug
		document.querySelectorAll('iframe').forEach(function(iframe){
			if (iframe.src.indexOf(slug) !== -1){
				// mark the iframe as active if it's on the results tab
				if (resultsTab){
					iframe.classList.add('active-iframe')
				}
			}
		})
	})
</script>	
</body>
</html>