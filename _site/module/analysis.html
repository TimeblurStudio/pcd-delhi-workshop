<!DOCTYPE html>
<html>
<head>

	<title>AUDIO ANALYSIS</title>
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/main.css">
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/highlighter.css">
	<script type="text/javascript" src="/pcd-delhi-workshop/scripts/prefixfree.min.js"></script>
</head>
<body>

	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/topbar.css">
<div id="topbar">
	<div id="links">
		<a href="/pcd-delhi-workshop/">home</a>
		<span>|</span>
		<a href="/pcd-delhi-workshop/syllabus">syllabus</a>
	</div>
	<div id="bar">
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
	</div>
</div>

	<h1>Audio Analysis</h1>

	<p>https://jackschaedler.github.io/circles-sines-signals/</p>

<p>Real-time audio analysis can be useful for coupling visuals to audio in interactive applications. There are a lot of libraries and acronyms when it comes to audio analysis, we’ll run through some of the most common analysis techniques and what sort of data they provide.</p>

<h3 id="rms---root-mean-square">RMS - Root Mean Square</h3>

<p>RMS is statistical measure defined as the square root of the mean of the squares of a sample. It is often in audio because it easily approximates loudness.</p>

<p>RMS gives you a single number which you can use to see about how loud the signal is.</p>

<h3 id="fft---fast-fourier-transform">FFT - Fast Fourier Transform</h3>

<p>The principle of Fourier Analysis is that all waves, no matter how complex can be decomposed into a collection of sine-tones at different frequencies and amplitudes. The “fast” part of FFT has to do with an efficient algorithm which makes it possible to do this type analysis in real time.</p>

<p><a href="https://www.youtube.com/watch?v=6dW6VYXp9HM">Mechanical Fourier Analysis</a></p>

<h4 id="analysisresynthesis">Analysis/Resynthesis</h4>

<p>So if you can decompose any sound into sine tones and amplitudes, then you should be able to recreate any sound from this analysis. That is the principle of Analysis/Resynthsis.</p>

<p>Full-blown Analysis/Resynthsis is pretty complicated because it requires many many oscillators (it might be a little too much for the Web Audio API to handle at the moment), but there is commercial software which does this sort of thing. One common one is called <a href="http://www.klingbeil.com/spear/">Spear</a></p>

<p><a href="https://www.youtube.com/watch?v=itAAezyj6wM">Analysis / Resynthesis Sculpture</a></p>

<h3 id="mfcc---mel-frequency-cepstrum">MFCC - Mel-frequency cepstrum</h3>

<p>MFCC is a representation of the short-term power spectrum of a sound on a nonlinear mel scale of frequency.</p>

<p>The mel scale, named by Stevens, Volkmann, and Newman in 1937, is a perceptual scale of pitches judged by listeners to be equal in distance from one another.</p>

<p>This means that the unlike the FFT, the Mel Scale is based on our perception of pitch which makes is why it’s often used in speech recognition and timbre analysis.</p>

<p><a href="https://hughrawlinson.github.io/meyda/">Meyda.js</a></p>

<h3 id="measurement-vs-perception">Measurement vs Perception</h3>

<p>We are very good at hearing. We can perceive complex harmonic sounds as having a “pitch” and find the beat in a clip of noisy music. Machine’s are not quite there. Remember there are big gaps between how the computer hears music and the way that we hear music. It cannot pick out instruments in a score and beat detection is difficult even with very complex algorithms.</p>

<h4 id="pitch-vs-frequency">Pitch vs Frequency</h4>

<p>Pitch = perception
Frequency = absolute</p>

<p>Objects often vibrate in harmonic multiples of a fundamental. Us humans would probably perceive that as a single pitch (and most likely we would hear the fundamental frequency as that pitch) while an FFT or oscilloscope would recognize the frequencies and energies of all the components of that note.</p>

<h5 id="pitch-detection">Pitch Detection</h5>

<p>Some of you have tried a few techniques already. It’s not so trivial. A (somewhat) simple algorithm to do pitch detection which can run in Javascript/Web Audio is <a href="https://en.wikipedia.org/wiki/Autocorrelation">autocorrelation</a></p>

<p><a href="https://webaudiodemos.appspot.com/pitchdetect/">pitch detect example</a></p>

<h4 id="beat-detection">Beat Detection</h4>

<p>Onset is another things which humans are good at which is much harder for a machine. It’s easy to tap your foot to a song even when there is a lot of noise in the recording while a computer would have a hard time differentiating the beats from the rest of the noises.</p>

<p><a href="http://tech.beatport.com/2014/web-audio/beat-detection-using-web-audio/">Here’s one way to do it</a></p>


	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/footer.css">
<div id='footnotes'>

</div>
<div id='footer'>
	©2019 PCD DELHI <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>

</div>

	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90915308-1', 'auto');
  ga('send', 'pageview');

</script>

	<script type="text/javascript">

	// jsfiddle creates too many AudioContexts, 
	// need to insure that the offscreen fiddles are closed
	// to remove the unused AudioContexts

	function isOffScreen (el) {
		var rect = el.getBoundingClientRect();
		return ((rect.left + rect.width) < 0 
			|| (rect.top + rect.height) < 0
			|| (rect.left > window.innerWidth || rect.top > window.innerHeight))
	}

	function reloadIframe(iframe){
		var url = iframe.src
		iframe.src = 'about:blank'
		setTimeout(function() {
			iframe.src = url
		}, 10)
	}

	//test the active elements to see if they are out of the viewport
	setInterval(function(){
		document.querySelectorAll('.active-iframe').forEach(function(el){
			if (isOffScreen(el)){
				reloadIframe(el)
				el.classList.remove('active-iframe')
			}
		})
	}, 1000)

	window.addEventListener('message', function(e){
		// if the results tab was selected
		var resultsTab = e.data[0] === 'resultsFrame'
		var slug = e.data[1].slug
		// get the iframe element using the slug
		document.querySelectorAll('iframe').forEach(function(iframe){
			if (iframe.src.indexOf(slug) !== -1){
				// mark the iframe as active if it's on the results tab
				if (resultsTab){
					iframe.classList.add('active-iframe')
				}
			}
		})
	})
</script>	
</body>
</html>