<!DOCTYPE html>
<html>
<head>

	<title>DIGITAL AUDIO</title>
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/main.css">
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/highlighter.css">
	<script type="text/javascript" src="/pcd-delhi-workshop/scripts/prefixfree.min.js"></script>
</head>
<body>

	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/topbar.css">
<div id="topbar">
	<div id="links">
		<a href="/pcd-delhi-workshop/">home</a>
		<span>|</span>
		<a href="/pcd-delhi-workshop/syllabus">workshop</a>
	</div>
	<div id="bar">
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
	</div>
</div>


	<h1>Digital Audio</h1>

	<h3 id="mixers-">Mixers (+)</h3>

<p>When two signals meet at a junction, the resulting signal is the sum of the inputs.</p>

<h3 id="gain-">Gain (*)</h3>

<p>Gain is the ratio between the input and the output signal.</p>

<h3 id="sampling">Sampling</h3>

<p>Continuous, analog values are converted to discrete digital events through sampling. The Nyquist Theorem states that the sampling rate needs to be at least twice the highest frequency to be reproduced.</p>

<p>Nyquist worked at Bell Labs and so did Max Matthews.</p>

<h3 id="aliasing">ALIASING</h3>

<p>Aliasing is an effect that causes different signals to become indistinguishable when sampled. When taking a video of a moving ceiling fan or car wheel you can get it to appear like it’s going backwards or much slower because the oscillation of the fan/wheel combined with the frame rate (sampling rate) of the camera.</p>

<h3 id="buffers">Buffers</h3>

<p>A buffer is an array. When audio is placed in a buffer and passed between sound producing/processing components.</p>

<h3 id="processing-graph">Processing Graph</h3>

<p>The chain of audio producing/processing components adds up to the processing graph.</p>

<h3 id="dac---digital-to-analog-converter">DAC - Digital-to-Analog Converter</h3>

<p>When audio is converted back into analog sound (like out your speaker), smoothing must be applied to get rid of the staircase effect between samples.</p>

<h3 id="noise-floor">Noise Floor</h3>

<p>The noise introduced by quantization error, including rounding errors and loss of precision introduced during audio processing, can be mitigated by adding a small amount of random noise, called dither, to the signal before quantizing. Dithering eliminates the granularity of quantization error, giving very low distortion, but at the expense of a slightly raised noise floor.</p>

<h2 id="daws">DAWs</h2>

<h3 id="channels">Channels</h3>

<p>Audio layers are arranged into channels with their own volume and pan controls. You can add effects to each channel.</p>

<h3 id="transport">Transport</h3>

<p>Play/Pause/Stop/Rewind/Loop</p>

<h3 id="automation">Automation</h3>

<p>Most DAWs let you automate nearly every parameter. A volume automation might be used to make an envelope or fade in/out.</p>


	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/footer.css">
<div id='footnotes'>

</div>
<div id='footer'>
	©2019 PCD, Delhi <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA </a>
	&
	©2017-2018 Yotam Mann <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>
</div>

	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90915308-1', 'auto');
  ga('send', 'pageview');

</script>

	<script type="text/javascript">

	// jsfiddle creates too many AudioContexts, 
	// need to insure that the offscreen fiddles are closed
	// to remove the unused AudioContexts

	function isOffScreen (el) {
		var rect = el.getBoundingClientRect();
		return ((rect.left + rect.width) < 0 
			|| (rect.top + rect.height) < 0
			|| (rect.left > window.innerWidth || rect.top > window.innerHeight))
	}

	function reloadIframe(iframe){
		var url = iframe.src
		iframe.src = 'about:blank'
		setTimeout(function() {
			iframe.src = url
		}, 10)
	}

	//test the active elements to see if they are out of the viewport
	setInterval(function(){
		document.querySelectorAll('.active-iframe').forEach(function(el){
			if (isOffScreen(el)){
				reloadIframe(el)
				el.classList.remove('active-iframe')
			}
		})
	}, 1000)

	window.addEventListener('message', function(e){
		// if the results tab was selected
		var resultsTab = e.data[0] === 'resultsFrame'
		var slug = e.data[1].slug
		// get the iframe element using the slug
		document.querySelectorAll('iframe').forEach(function(iframe){
			if (iframe.src.indexOf(slug) !== -1){
				// mark the iframe as active if it's on the results tab
				if (resultsTab){
					iframe.classList.add('active-iframe')
				}
			}
		})
	})
</script>	
</body>
</html>