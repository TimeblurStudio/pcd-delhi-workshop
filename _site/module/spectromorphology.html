<!DOCTYPE html>
<html>
<head>

	<title>SPECTROMORPHOLOGY</title>
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/main.css">
	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/highlighter.css">
	<script type="text/javascript" src="/pcd-delhi-workshop/scripts/prefixfree.min.js"></script>
</head>
<body>

	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/topbar.css">
<div id="topbar">
	<div id="links">
		<a href="/pcd-delhi-workshop/">home</a>
		<span>|</span>
		<a href="/pcd-delhi-workshop/syllabus">workshop</a>
	</div>
	<div id="bar">
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
			<span></span>
		
	</div>
</div>


	<h1>Spectromorphology</h1>

	<blockquote>
  <p>Spectromorphology is the perceived sonic footprint of a sound spectrum as it manifests in time.</p>
</blockquote>

<p><a href="/pcd-delhi-workshop/pdfs/Spectromorphology Explaining Sound Shapes_ D. Smalley.pdf">Spectromorphology</a> is also the name of a very famous paper published in 1986 by Denis Smalley.</p>

<p>All quotes are from Denis Smalley unless otherwise noted.</p>

<blockquote>
  <p>I have developed the concepts and terminology spectromorphology as tools for describing and  analysing listening experience. The two parts of the  term refer to the interaction between sound spectra (spectro-) and the ways they change and are shaped through time (-morphology). The spectro- cannot exist without the -morphology and vice versa: something has to be shaped, and a shape must have sonic content.</p>
</blockquote>

<p>Addresses the inadequacy of traditional notation in capturing the endless sound-generating possibilities of computers. It grapples with similar topics as we covered in the graphic notation module, if we can’t abstract sounds into instruments/notes/rhythms, how can we compose and reason about them?</p>

<blockquote>
  <p>Spectromorphology is not a compositional theory or method, but a descriptive tool based on aural perception. It is intended to aid listening, and seeks to help explain what can be apprehended in over four decades of electroacoustic repertory. How composers conceive musical content and form – their aims, models, systems, techniques, and structural plans…</p>
</blockquote>

<blockquote>
  <p>Until the electroacoustic medium arrived, all music was created either through forms of vocal utterance or through instrumental gesture. A human agent produces spectromorphologies via the motion of gesture, using the sense of touch or an implement to apply energy to a sounding body. A gesture is therefore an energy–motion trajectory which excites the sounding body, creating spectromorphological life.</p>
</blockquote>

<h2 id="intrinsicextrinsic-threads">Intrinsic–extrinsic threads</h2>

<blockquote>
  <p>Spectromorphology concentrates on intrinsic features. That is, it is an aid to describing sound events and their relationships as they exist within a piece of music. However, a piece of music is not a closed, autonomous artefact: it does not refer only to itself but relies on relating to a range of experiences outside the context of the work. Music is a cultural construct, and an extrinsic foundation in culture is necessary so that the intrinsic can have meaning. The intrinsic and extrinsic are interactive.</p>
</blockquote>

<h2 id="source-bonding">Source Bonding</h2>

<blockquote>
  <p>traditionally, all cultures have considerable knowledge about how sounds are made as a result of continuing visual observation and listening. Once we can grasp the relationship between the sounding body and the cause of the sound we feel we have captured a certain understanding: intuitive knowledge of the human physical gesture involved is inextricably bound up with our knowledge of music as an <em>activity</em>.</p>
</blockquote>

<p>Associating sounds sources with what is perceived to have created that sound.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/71hNl_skTZQ?start=0" frameborder="0" allowfullscreen="">
</iframe>

<h2 id="gesture-and-its-surrogates">Gesture and Its Surrogates</h2>

<blockquote>
  <p>Until the electroacoustic medium arrived, all music was created either through forms of vocal utterance or through instrumental gesture. Sound-making gesture is concerned with human, physical activity which has spectromorphological consequences: a chain of activity links a cause to a source.</p>
</blockquote>

<p>Smalley breaks down the cause–source–spectromorphology into three levels of abstraction/surrogacy</p>

<blockquote>
  <p>First-order surrogacy projects the primal level into sound, and is concerned with sonic object use in work and play prior to any ‘instrumentalisation’ or incorporation into a musical activity or structure. It is here that musical potential begins to be recognised and explored.</p>
</blockquote>

<blockquote>
  <p>Second-order surrogacy is traditional instrumental gesture, a stage removed from the first order, where recognisable performance skill has been used to develop an extensive registral articulatory play.</p>
</blockquote>

<blockquote>
  <p>Third-order surrogacy is where a gesture is inferred or imagined in the music. The nature of the spectromorphology makes us unsure about the reality of either the source or the cause, or both.</p>
</blockquote>

<blockquote>
  <p>Remote surrogacy is concerned with gestural vestiges. Source and cause become unknown and unknowable as any human action behind the sound disappears.</p>
</blockquote>

<h2 id="onset-continuant-and-termination">Onset, Continuant and Termination</h2>

<blockquote>
  <p>Every note must start in some way; some may be sustained or prolonged for a time and some may not; every note stops.</p>
</blockquote>

<ul>
  <li>attack-impulse. Modeled on the single detached note: a sudden onset which is immediately terminated.  A dry percussive attack or a staccato sound (without resonance)</li>
  <li>attack-decay (closed and open) - modeled on sounds in which the attack-onset is extended by a resonance that quickly or gradually decays towards termination. The closed form represents a quick decay which is strongly attack-determined. A string pizzicato or a bell.</li>
  <li>graduated continuant - Modeled on sustained sounds. The onset is graduated, settling into a continuant phase which eventually closes in a graduated termination. Sustained string or wind sounds.</li>
</ul>

<blockquote>
  <p>Variants are created by manipulating the durations and spectral energy of the three phases.</p>
</blockquote>



	<link rel="stylesheet" type="text/css" href="/pcd-delhi-workshop/style/footer.css">
<div id='footnotes'>

</div>
<div id='footer'>
	©2019 PCD, Delhi <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA </a>
	&
	©2017-2018 Yotam Mann <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>
</div>

	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90915308-1', 'auto');
  ga('send', 'pageview');

</script>

	<script type="text/javascript">

	// jsfiddle creates too many AudioContexts, 
	// need to insure that the offscreen fiddles are closed
	// to remove the unused AudioContexts

	function isOffScreen (el) {
		var rect = el.getBoundingClientRect();
		return ((rect.left + rect.width) < 0 
			|| (rect.top + rect.height) < 0
			|| (rect.left > window.innerWidth || rect.top > window.innerHeight))
	}

	function reloadIframe(iframe){
		var url = iframe.src
		iframe.src = 'about:blank'
		setTimeout(function() {
			iframe.src = url
		}, 10)
	}

	//test the active elements to see if they are out of the viewport
	setInterval(function(){
		document.querySelectorAll('.active-iframe').forEach(function(el){
			if (isOffScreen(el)){
				reloadIframe(el)
				el.classList.remove('active-iframe')
			}
		})
	}, 1000)

	window.addEventListener('message', function(e){
		// if the results tab was selected
		var resultsTab = e.data[0] === 'resultsFrame'
		var slug = e.data[1].slug
		// get the iframe element using the slug
		document.querySelectorAll('iframe').forEach(function(iframe){
			if (iframe.src.indexOf(slug) !== -1){
				// mark the iframe as active if it's on the results tab
				if (resultsTab){
					iframe.classList.add('active-iframe')
				}
			}
		})
	})
</script>	
</body>
</html>